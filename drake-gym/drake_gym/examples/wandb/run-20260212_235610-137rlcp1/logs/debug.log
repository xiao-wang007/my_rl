2026-02-12 23:56:10,274 INFO    MainThread:63869 [wandb_setup.py:_flush():81] Current SDK version is 0.24.1
2026-02-12 23:56:10,274 INFO    MainThread:63869 [wandb_setup.py:_flush():81] Configure stats pid to 63869
2026-02-12 23:56:10,274 INFO    MainThread:63869 [wandb_setup.py:_flush():81] Loading settings from environment variables
2026-02-12 23:56:10,274 INFO    MainThread:63869 [wandb_init.py:setup_run_log_directory():717] Logging user logs to /Users/xiao/0_codes/my_rl/drake-gym/drake_gym/examples/wandb/run-20260212_235610-137rlcp1/logs/debug.log
2026-02-12 23:56:10,274 INFO    MainThread:63869 [wandb_init.py:setup_run_log_directory():718] Logging internal logs to /Users/xiao/0_codes/my_rl/drake-gym/drake_gym/examples/wandb/run-20260212_235610-137rlcp1/logs/debug-internal.log
2026-02-12 23:56:10,276 INFO    MainThread:63869 [wandb_init.py:init():844] calling init triggers
2026-02-12 23:56:10,276 INFO    MainThread:63869 [wandb_init.py:init():849] wandb.init called with sweep_config: {}
config: {'policy_type': 'MlpPolicy', 'total_timesteps': 500000.0, 'env_name': 'panda-reach-v0', 'env_time_limit': 10, 'local_log_dir': 'logs/panda_reach_ppo', 'observations': 'state', 'net_arch': [128, 128], 'custom_net': True, 'v_max_scale': 1.0, 'batch_size': 2048, 'n_steps': 2048, '_wandb': {'code_path': 'code/drake-gym/drake_gym/examples/train_franka_reach_PPO.py'}}
2026-02-12 23:56:10,276 INFO    MainThread:63869 [wandb_init.py:init():892] starting backend
2026-02-12 23:56:10,515 INFO    MainThread:63869 [wandb_init.py:init():895] sending inform_init request
2026-02-12 23:56:10,541 INFO    MainThread:63869 [wandb_init.py:init():903] backend started and connected
2026-02-12 23:56:10,544 INFO    MainThread:63869 [wandb_init.py:init():973] updated telemetry
2026-02-12 23:56:10,561 INFO    MainThread:63869 [wandb_init.py:init():997] communicating run to backend with 90.0 second timeout
2026-02-12 23:56:11,081 INFO    MainThread:63869 [wandb_init.py:init():1042] starting run threads in backend
2026-02-12 23:56:11,135 INFO    MainThread:63869 [wandb_run.py:_console_start():2529] atexit reg
2026-02-12 23:56:11,135 INFO    MainThread:63869 [wandb_run.py:_redirect():2377] redirect: wrap_raw
2026-02-12 23:56:11,135 INFO    MainThread:63869 [wandb_run.py:_redirect():2446] Wrapping output streams.
2026-02-12 23:56:11,136 INFO    MainThread:63869 [wandb_run.py:_redirect():2469] Redirects installed.
2026-02-12 23:56:11,137 INFO    MainThread:63869 [wandb_init.py:init():1082] run started, returning control to user process
2026-02-12 23:56:13,482 INFO    MainThread:63869 [wandb_run.py:_tensorboard_callback():1615] tensorboard callback: runs/137rlcp1/PPO_1, True
2026-02-12 23:56:13,484 INFO    MainThread:63869 [wandb_run.py:_config_callback():1404] config_cb None None {'algo': 'PPO', 'policy_class': "<class 'stable_baselines3.common.policies.ActorCriticPolicy'>", 'device': 'cpu', 'verbose': 1, 'policy_kwargs': "{'net_arch': [128, 128], 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>}", 'num_timesteps': 0, '_total_timesteps': 6000000.0, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'None', 'start_time': 1770940573480465000, 'learning_rate': 0.0003, 'tensorboard_log': 'runs/137rlcp1', '_last_obs': '[[ 0.65096337  0.47966993 -1.1908367  -2.5562067   0.11963882  2.6114225\n   1.5789756   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 0.81444913 -0.05455464 -1.0749166  -2.0101748   0.0291436   2.041877\n   2.3987665   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 0.57092214  0.53802073 -0.6002369  -2.0242124   0.05707079  1.6308439\n   2.2042663   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 0.8185299   0.0947515  -0.54994047 -1.8857579  -0.09060239  1.9251444\n   1.9066783   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 0.9142886   0.4054192  -1.4261986  -2.360503    0.06320037  2.0585072\n   1.8725709   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 1.4071805   0.4161791  -0.4577766  -2.1881764  -0.01816593  2.2719586\n   2.2699745   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 0.86174166  0.53394336 -0.9607633  -2.197906    0.36823475  1.7267674\n   2.151826    0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 0.5232617   0.22170606 -0.7497649  -1.959946    0.60263234  2.567725\n   2.4973054   0.          0.          0.          0.          0.\n   0.          0.        ]]', '_last_episode_starts': '[ True  True  True  True  True  True  True  True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x1458b6c60>', '_vec_normalize_env': 'None', 'observation_space': 'Box(-inf, inf, (14,), float32)', 'action_space': 'Box(-1.0, 1.0, (7,), float32)', 'n_envs': 8, 'gamma': 0.99, 'gae_lambda': 0.95, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'rollout_buffer_class': "<class 'stable_baselines3.common.buffers.RolloutBuffer'>", 'rollout_buffer_kwargs': '{}', 'n_epochs': 10, 'clip_range': 'FloatSchedule(ConstantSchedule(val=0.2))', 'clip_range_vf': 'None', 'normalize_advantage': 'True', 'target_kl': 'None', 'lr_schedule': 'FloatSchedule(ConstantSchedule(val=0.0003))', 'rollout_buffer': '<stable_baselines3.common.buffers.RolloutBuffer object at 0x1456231a0>', 'policy': 'ActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=14, out_features=128, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=128, out_features=128, bias=True)\n      (3): ReLU()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=14, out_features=128, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=128, out_features=128, bias=True)\n      (3): ReLU()\n    )\n  )\n  (action_net): Linear(in_features=128, out_features=7, bias=True)\n  (value_net): Linear(in_features=128, out_features=1, bias=True)\n)', '_logger': '<stable_baselines3.common.logger.Logger object at 0x159abdb80>'}
2026-02-13 00:26:20,043 INFO    wandb-AsyncioManager-main:63869 [service_client.py:_forward_responses():94] Reached EOF.
2026-02-13 00:26:20,043 INFO    wandb-AsyncioManager-main:63869 [mailbox.py:close():154] Closing mailbox, abandoning 1 handles.
