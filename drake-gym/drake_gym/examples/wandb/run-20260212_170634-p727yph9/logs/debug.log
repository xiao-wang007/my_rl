2026-02-12 17:06:34,107 INFO    MainThread:51274 [wandb_setup.py:_flush():81] Current SDK version is 0.24.1
2026-02-12 17:06:34,107 INFO    MainThread:51274 [wandb_setup.py:_flush():81] Configure stats pid to 51274
2026-02-12 17:06:34,107 INFO    MainThread:51274 [wandb_setup.py:_flush():81] Loading settings from environment variables
2026-02-12 17:06:34,107 INFO    MainThread:51274 [wandb_init.py:setup_run_log_directory():717] Logging user logs to /Users/xiao/0_codes/my_rl/drake-gym/drake_gym/examples/wandb/run-20260212_170634-p727yph9/logs/debug.log
2026-02-12 17:06:34,108 INFO    MainThread:51274 [wandb_init.py:setup_run_log_directory():718] Logging internal logs to /Users/xiao/0_codes/my_rl/drake-gym/drake_gym/examples/wandb/run-20260212_170634-p727yph9/logs/debug-internal.log
2026-02-12 17:06:34,110 INFO    MainThread:51274 [wandb_init.py:init():844] calling init triggers
2026-02-12 17:06:34,110 INFO    MainThread:51274 [wandb_init.py:init():849] wandb.init called with sweep_config: {}
config: {'policy_type': 'MlpPolicy', 'total_timesteps': 500000.0, 'env_name': 'panda-reach-v0', 'env_time_limit': 10, 'local_log_dir': 'logs/panda_reach_ppo', 'observations': 'state', 'net_arch': [128, 128], 'custom_net': True, 'v_max_scale': 1.0, 'batch_size': 2048, 'n_steps': 2048, '_wandb': {'code_path': 'code/drake-gym/drake_gym/examples/train_franka_reach_PPO.py'}}
2026-02-12 17:06:34,110 INFO    MainThread:51274 [wandb_init.py:init():892] starting backend
2026-02-12 17:06:34,342 INFO    MainThread:51274 [wandb_init.py:init():895] sending inform_init request
2026-02-12 17:06:34,370 INFO    MainThread:51274 [wandb_init.py:init():903] backend started and connected
2026-02-12 17:06:34,372 INFO    MainThread:51274 [wandb_init.py:init():973] updated telemetry
2026-02-12 17:06:34,389 INFO    MainThread:51274 [wandb_init.py:init():997] communicating run to backend with 90.0 second timeout
2026-02-12 17:06:35,062 INFO    MainThread:51274 [wandb_init.py:init():1042] starting run threads in backend
2026-02-12 17:06:35,108 INFO    MainThread:51274 [wandb_run.py:_console_start():2529] atexit reg
2026-02-12 17:06:35,108 INFO    MainThread:51274 [wandb_run.py:_redirect():2377] redirect: wrap_raw
2026-02-12 17:06:35,108 INFO    MainThread:51274 [wandb_run.py:_redirect():2446] Wrapping output streams.
2026-02-12 17:06:35,108 INFO    MainThread:51274 [wandb_run.py:_redirect():2469] Redirects installed.
2026-02-12 17:06:35,110 INFO    MainThread:51274 [wandb_init.py:init():1082] run started, returning control to user process
2026-02-12 17:06:37,499 INFO    MainThread:51274 [wandb_run.py:_tensorboard_callback():1615] tensorboard callback: runs/p727yph9/PPO_1, True
2026-02-12 17:06:37,501 INFO    MainThread:51274 [wandb_run.py:_config_callback():1404] config_cb None None {'algo': 'PPO', 'policy_class': "<class 'stable_baselines3.common.policies.ActorCriticPolicy'>", 'device': 'cpu', 'verbose': 1, 'policy_kwargs': "{'net_arch': [128, 128], 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>}", 'num_timesteps': 0, '_total_timesteps': 6000000.0, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'None', 'start_time': 1770915997496872000, 'learning_rate': 0.0003, 'tensorboard_log': 'runs/p727yph9', '_last_obs': '[[ 1.2206538   0.53345454 -1.1862935  -2.0453649   0.2992614   2.5564532\n   1.8175678   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 0.48387918 -0.13519892 -1.101259   -2.3268518   0.6462128   2.2599316\n   2.3822656   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 1.2445943   0.10436633 -1.1466568  -2.259279    0.43187714  1.7593666\n   2.1612105   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 1.1803216  -0.03566793 -1.3722663  -2.5646272   0.05139402  2.2709212\n   1.7770355   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 1.3584049   0.7296266  -1.2705879  -2.3121068   0.60109085  1.6966265\n   2.0920177   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 0.96098626  0.47108796 -1.1695824  -1.7103858   0.7409602   1.8891098\n   2.1440475   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 1.3316832   0.00648989 -0.59835213 -1.966459   -0.17921665  2.2191446\n   2.02862     0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 0.4217044   0.6352683  -0.5991615  -2.5540557   0.20028222  2.6137643\n   2.075272    0.          0.          0.          0.          0.\n   0.          0.        ]]', '_last_episode_starts': '[ True  True  True  True  True  True  True  True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x14472e2a0>', '_vec_normalize_env': 'None', 'observation_space': 'Box(-inf, inf, (14,), float32)', 'action_space': 'Box(-1.0, 1.0, (7,), float32)', 'n_envs': 8, 'gamma': 0.99, 'gae_lambda': 0.95, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'rollout_buffer_class': "<class 'stable_baselines3.common.buffers.RolloutBuffer'>", 'rollout_buffer_kwargs': '{}', 'n_epochs': 10, 'clip_range': 'FloatSchedule(ConstantSchedule(val=0.2))', 'clip_range_vf': 'None', 'normalize_advantage': 'True', 'target_kl': 'None', 'lr_schedule': 'FloatSchedule(ConstantSchedule(val=0.0003))', 'rollout_buffer': '<stable_baselines3.common.buffers.RolloutBuffer object at 0x144e51df0>', 'policy': 'ActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=14, out_features=128, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=128, out_features=128, bias=True)\n      (3): ReLU()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=14, out_features=128, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=128, out_features=128, bias=True)\n      (3): ReLU()\n    )\n  )\n  (action_net): Linear(in_features=128, out_features=7, bias=True)\n  (value_net): Linear(in_features=128, out_features=1, bias=True)\n)', '_logger': '<stable_baselines3.common.logger.Logger object at 0x1587e7e30>'}
2026-02-12 17:34:23,938 INFO    wandb-AsyncioManager-main:51274 [service_client.py:_forward_responses():94] Reached EOF.
2026-02-12 17:34:23,938 INFO    wandb-AsyncioManager-main:51274 [mailbox.py:close():154] Closing mailbox, abandoning 1 handles.
