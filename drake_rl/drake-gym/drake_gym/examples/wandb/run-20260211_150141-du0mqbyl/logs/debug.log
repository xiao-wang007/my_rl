2026-02-11 15:01:41,328 INFO    MainThread:23910 [wandb_setup.py:_flush():81] Current SDK version is 0.24.1
2026-02-11 15:01:41,328 INFO    MainThread:23910 [wandb_setup.py:_flush():81] Configure stats pid to 23910
2026-02-11 15:01:41,328 INFO    MainThread:23910 [wandb_setup.py:_flush():81] Loading settings from environment variables
2026-02-11 15:01:41,328 INFO    MainThread:23910 [wandb_init.py:setup_run_log_directory():717] Logging user logs to /Users/xiao/0_codes/my_rl/drake-gym/drake_gym/examples/wandb/run-20260211_150141-du0mqbyl/logs/debug.log
2026-02-11 15:01:41,328 INFO    MainThread:23910 [wandb_init.py:setup_run_log_directory():718] Logging internal logs to /Users/xiao/0_codes/my_rl/drake-gym/drake_gym/examples/wandb/run-20260211_150141-du0mqbyl/logs/debug-internal.log
2026-02-11 15:01:41,330 INFO    MainThread:23910 [wandb_init.py:init():844] calling init triggers
2026-02-11 15:01:41,330 INFO    MainThread:23910 [wandb_init.py:init():849] wandb.init called with sweep_config: {}
config: {'policy_type': 'MlpPolicy', 'total_timesteps': 500000.0, 'env_name': 'panda-reach-v0', 'env_time_limit': 10, 'local_log_dir': 'logs/panda_reach_ppo', 'observations': 'state', 'net_arch': [128, 128], 'custom_net': True, 'v_max_scale': 1.0, 'batch_size': 2048, 'n_steps': 2048, '_wandb': {'code_path': 'code/drake-gym/drake_gym/examples/train_franka_reach_PPO.py'}}
2026-02-11 15:01:41,330 INFO    MainThread:23910 [wandb_init.py:init():892] starting backend
2026-02-11 15:01:41,559 INFO    MainThread:23910 [wandb_init.py:init():895] sending inform_init request
2026-02-11 15:01:41,586 INFO    MainThread:23910 [wandb_init.py:init():903] backend started and connected
2026-02-11 15:01:41,589 INFO    MainThread:23910 [wandb_init.py:init():973] updated telemetry
2026-02-11 15:01:41,606 INFO    MainThread:23910 [wandb_init.py:init():997] communicating run to backend with 90.0 second timeout
2026-02-11 15:01:42,218 INFO    MainThread:23910 [wandb_init.py:init():1042] starting run threads in backend
2026-02-11 15:01:42,267 INFO    MainThread:23910 [wandb_run.py:_console_start():2529] atexit reg
2026-02-11 15:01:42,267 INFO    MainThread:23910 [wandb_run.py:_redirect():2377] redirect: wrap_raw
2026-02-11 15:01:42,267 INFO    MainThread:23910 [wandb_run.py:_redirect():2446] Wrapping output streams.
2026-02-11 15:01:42,267 INFO    MainThread:23910 [wandb_run.py:_redirect():2469] Redirects installed.
2026-02-11 15:01:42,269 INFO    MainThread:23910 [wandb_init.py:init():1082] run started, returning control to user process
2026-02-11 15:01:44,654 INFO    MainThread:23910 [wandb_run.py:_tensorboard_callback():1615] tensorboard callback: runs/du0mqbyl/PPO_1, True
2026-02-11 15:01:44,656 INFO    MainThread:23910 [wandb_run.py:_config_callback():1404] config_cb None None {'algo': 'PPO', 'policy_class': "<class 'stable_baselines3.common.policies.ActorCriticPolicy'>", 'device': 'cpu', 'verbose': 1, 'policy_kwargs': "{'net_arch': [128, 128], 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>}", 'num_timesteps': 0, '_total_timesteps': 6000000.0, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'None', 'start_time': 1770822104651883000, 'learning_rate': 0.0003, 'tensorboard_log': 'runs/du0mqbyl', '_last_obs': '[[ 0.5953185  -0.01832325 -1.3466355  -2.3044593   0.5386146   2.5427177\n   2.169028    0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 1.052471    0.42522946 -0.66086507 -1.7647316  -0.14203306  2.528103\n   2.0976777   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 0.9049935   0.3205649  -0.60358703 -2.2261398  -0.18081246  2.5416255\n   2.2309737   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 0.748879    0.38998088 -1.1766796  -1.9994963   0.28727302  2.576397\n   2.1654177   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 1.090803    0.38057318 -1.3459911  -2.096592    0.45870236  2.5165212\n   2.434094    0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 0.9931382   0.70467836 -0.48639446 -2.146393    0.2375203   2.5172367\n   1.5852332   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 1.3284175   0.4988645  -0.57695717 -2.4139762   0.342549    1.8880155\n   1.9821119   0.          0.          0.          0.          0.\n   0.          0.        ]\n [ 0.95385826  0.02439545 -0.47006506 -1.9395828   0.1661332   2.5486143\n   1.851354    0.          0.          0.          0.          0.\n   0.          0.        ]]', '_last_episode_starts': '[ True  True  True  True  True  True  True  True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x16342e840>', '_vec_normalize_env': 'None', 'observation_space': 'Box(-inf, inf, (14,), float32)', 'action_space': 'Box(-1.0, 1.0, (7,), float32)', 'n_envs': 8, 'gamma': 0.99, 'gae_lambda': 0.95, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'rollout_buffer_class': "<class 'stable_baselines3.common.buffers.RolloutBuffer'>", 'rollout_buffer_kwargs': '{}', 'n_epochs': 10, 'clip_range': 'FloatSchedule(ConstantSchedule(val=0.2))', 'clip_range_vf': 'None', 'normalize_advantage': 'True', 'target_kl': 'None', 'lr_schedule': 'FloatSchedule(ConstantSchedule(val=0.0003))', 'rollout_buffer': '<stable_baselines3.common.buffers.RolloutBuffer object at 0x163d53ef0>', 'policy': 'ActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=14, out_features=128, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=128, out_features=128, bias=True)\n      (3): ReLU()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=14, out_features=128, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=128, out_features=128, bias=True)\n      (3): ReLU()\n    )\n  )\n  (action_net): Linear(in_features=128, out_features=7, bias=True)\n  (value_net): Linear(in_features=128, out_features=1, bias=True)\n)', '_logger': '<stable_baselines3.common.logger.Logger object at 0x1685b5df0>'}
2026-02-11 15:29:28,250 INFO    wandb-AsyncioManager-main:23910 [service_client.py:_forward_responses():94] Reached EOF.
2026-02-11 15:29:28,250 INFO    wandb-AsyncioManager-main:23910 [mailbox.py:close():154] Closing mailbox, abandoning 1 handles.
