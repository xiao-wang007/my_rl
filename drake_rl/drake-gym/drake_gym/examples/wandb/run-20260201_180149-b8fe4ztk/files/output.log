Using mps device
/Users/xiao/miniforge3/envs/robotics/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
Logging to runs/b8fe4ztk/PPO_1
[2K---------------------------------â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12,174/3,000,000 [0m [ [33m0:00:11[0m < [36m0:44:47[0m , [31m1,112 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 5.34     |
|    ep_rew_mean     | 21.3     |
| time/              |          |
|    fps             | 1102     |
|    iterations      | 1        |
|    time_elapsed    | 11       |
|    total_timesteps | 12288    |
---------------------------------
[2K-----------------------------------------8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m24,528/3,000,000 [0m [ [33m0:00:36[0m < [36m1:28:59[0m , [31m557 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 4.33        |
|    ep_rew_mean          | 7.02        |
| time/                   |             |
|    fps                  | 666         |
|    iterations           | 2           |
|    time_elapsed         | 36          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.007370183 |
|    clip_fraction        | 0.0862      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.94       |
|    explained_variance   | 0.00499     |
|    learning_rate        | 0.0003      |
|    loss                 | 332         |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00273    |
|    std                  | 1           |
|    value_loss           | 386         |
-----------------------------------------
[2K-----------------------------------------8;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m36,648/3,000,000 [0m [ [33m0:01:02[0m < [36m1:24:42[0m , [31m583 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 4.06        |
|    ep_rew_mean          | 6.57        |
| time/                   |             |
|    fps                  | 593         |
|    iterations           | 3           |
|    time_elapsed         | 62          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.008942391 |
|    clip_fraction        | 0.0897      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | 0.206       |
|    learning_rate        | 0.0003      |
|    loss                 | 19          |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00372    |
|    std                  | 0.993       |
|    value_loss           | 153         |
-----------------------------------------
[2K----------------------------------------[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m49,056/3,000,000 [0m [ [33m0:01:26[0m < [36m1:17:34[0m , [31m634 it/s[0m ]s[0m ]
| rollout/                |            |
|    ep_len_mean          | 3.6        |
|    ep_rew_mean          | 6.47       |
| time/                   |            |
|    fps                  | 566        |
|    iterations           | 4          |
|    time_elapsed         | 86         |
|    total_timesteps      | 49152      |
| train/                  |            |
|    approx_kl            | 0.00818084 |
|    clip_fraction        | 0.0856     |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.87      |
|    explained_variance   | 0.209      |
|    learning_rate        | 0.0003     |
|    loss                 | 399        |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.00305   |
|    std                  | 0.991      |
|    value_loss           | 248        |
----------------------------------------
[2K-----------------------------------------38;2;249;38;114mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m61,398/3,000,000 [0m [ [33m0:01:51[0m < [36m1:19:20[0m , [31m617 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 3.95        |
|    ep_rew_mean          | 7.22        |
| time/                   |             |
|    fps                  | 549         |
|    iterations           | 5           |
|    time_elapsed         | 111         |
|    total_timesteps      | 61440       |
| train/                  |             |
|    approx_kl            | 0.010219355 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.197       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.69        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00458    |
|    std                  | 0.99        |
|    value_loss           | 108         |
-----------------------------------------
[2K----------------------------------------[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m73,554/3,000,000 [0m [ [33m0:02:17[0m < [36m1:26:24[0m , [31m565 it/s[0m ]s[0m ]
| rollout/                |            |
|    ep_len_mean          | 3.97       |
|    ep_rew_mean          | 7.28       |
| time/                   |            |
|    fps                  | 535        |
|    iterations           | 6          |
|    time_elapsed         | 137        |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 0.01038703 |
|    clip_fraction        | 0.101      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.83      |
|    explained_variance   | 0.325      |
|    learning_rate        | 0.0003     |
|    loss                 | 66.8       |
|    n_updates            | 50         |
|    policy_gradient_loss | -0.00417   |
|    std                  | 0.983      |
|    value_loss           | 83.1       |
----------------------------------------
[2KTraceback (most recent call last):â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m78,132/3,000,000 [0m [ [33m0:02:36[0m < [36m1:27:19[0m , [31m558 it/s[0m ]
[2K  File "/Users/xiao/0_codes/my_rl/drake-gym/drake_gym/examples/train_franka_reach_PPO.py", line 265, in <module>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m78,132/3,000,000 [0m [ [33m0:02:36[0m < [36m1:27:19[0m , [31m558 it/s[0m ]
    sys.exit(main())
             ^^^^^^
[2K  File "/Users/xiao/0_codes/my_rl/drake-gym/drake_gym/examples/train_franka_reach_PPO.py", line 257, in mainâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m78,132/3,000,000 [0m [ [33m0:02:36[0m < [36m1:27:19[0m , [31m558 it/s[0m ]
    model.learn(
[2K  File "/Users/xiao/miniforge3/envs/robotics/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learnâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m78,132/3,000,000 [0m [ [33m0:02:36[0m < [36m1:27:19[0m , [31m558 it/s[0m ]
    return super().learn(
           ^^^^^^^^^^^^^^
[2K  File "/Users/xiao/miniforge3/envs/robotics/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learnâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m78,132/3,000,000 [0m [ [33m0:02:36[0m < [36m1:27:19[0m , [31m558 it/s[0m ]
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/Users/xiao/miniforge3/envs/robotics/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 247, in collect_rolloutsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m78,132/3,000,000 [0m [ [33m0:02:36[0m < [36m1:27:19[0m , [31m558 it/s[0m ]
    rollout_buffer.add(
[2K  File "/Users/xiao/miniforge3/envs/robotics/lib/python3.12/site-packages/stable_baselines3/common/buffers.py", line 475, in addâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m78,132/3,000,000 [0m [ [33m0:02:36[0m < [36m1:27:19[0m , [31m558 it/s[0m ]
    self.values[self.pos] = value.clone().cpu().numpy().flatten()
                            ^^^^^^^^^^^^^^^^^^^
[2KKeyboardInterrupt;249;38;114mâ”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m78,132/3,000,000 [0m [ [33m0:02:36[0m < [36m1:27:19[0m , [31m558 it/s[0m ]
[35m   3%[0m [38;2;249;38;114mâ”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m78,132/3,000,000 [0m [ [33m0:02:36[0m < [36m1:27:19[0m , [31m558 it/s[0m ]
